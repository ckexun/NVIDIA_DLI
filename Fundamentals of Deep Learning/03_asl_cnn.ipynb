{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weabkZTF3ZZM"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz8YI6Fb3ZZN"
   },
   "source": [
    "# 3. 卷積神經網路(Convolutional Neural Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UWR4l4X3ZZN"
   },
   "source": [
    "在前一節中，我們建立並訓練了一個簡單的模型來分類美國手語(ASL)圖像。該模型能夠以非常高的準確度(accuracy)正確地學習分類訓練資料集，但它在驗證(Validation)資料集上的表現卻不那麼好。這種無法很好地泛化到非訓練資料的行為稱為過度擬合([overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html))，在本節中，我們將介紹一種稱為卷積神經網路([convolutional neural network](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53))的常見模型，它特別擅長讀取圖像並對其進行分類。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmRLS07k3ZZN"
   },
   "source": [
    "## 3.1 目標(Objectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iuvwj_tr3ZZN"
   },
   "source": [
    "* 專門為卷積神經網路(CNN)準備資料\n",
    "* 創建一個更複雜的卷積神經網路(CNN)模型，了解更多種類的模型層\n",
    "* 訓練卷積神經網路(CNN)模型並觀察其性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1715240535370,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "9kMRTHEV2AFm",
    "outputId": "f1fb3858-e6a7-4906-ec7e-c4d34abcf013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEGukATl3ZZN"
   },
   "source": [
    "## 3.2 載入和準備資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 準備圖像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SyD7hID3ZZN"
   },
   "source": [
    "\n",
    "讓我們像在前一個課程練習(Lab)中那樣載入我們的 DataFrames："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3372,
     "status": "ok",
     "timestamp": 1715240541334,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "XMMgEMcc2Ehg"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"data/asl_data/sign_mnist_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "這個美國手語(ASL)資料已經事先被扁平化了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107, 118, 127, ..., 204, 203, 202],\n",
       "       [155, 157, 156, ..., 103, 135, 149],\n",
       "       [187, 188, 188, ..., 195, 194, 195],\n",
       "       [211, 211, 212, ..., 222, 229, 163],\n",
       "       [164, 167, 170, ..., 163, 164, 179]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = train_df.head().copy()  # Grab the top 5 rows\n",
    "sample_df.pop('label')\n",
    "sample_x = sample_df.values\n",
    "sample_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在這種格式下，我們沒有關於哪些像素彼此相鄰的所有資訊。因此，我們無法應用能夠檢測特徵的卷積。讓我們重塑([reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html))我們的資料集，使其採用28x28像素的格式。這將使我們的卷積能夠關聯像素組並檢測重要特徵。\n",
    "\n",
    "請注意，對於我們模型的第一個卷積層，我們不僅需要圖像的高度和寬度，還需要顏色通道([color channels](https://www.photoshopessentials.com/essentials/rgb/))的數量。我們的圖像是灰階的，所以我們只有1個通道(channel)。\n",
    "\n",
    "這意味著我們需要將目前的形狀 `(5, 784)` 轉換為 `(5, 1, 28, 28)`。使用 [NumPy](https://numpy.org/doc/stable/index.html) 陣列，我們可以為任何我們希望保持不變的維度使用`-1`作為設定值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "IMG_CHS = 1\n",
    "\n",
    "sample_x = sample_x.reshape(-1, IMG_CHS, IMG_HEIGHT, IMG_WIDTH)\n",
    "sample_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 創建資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讓我們將上述步驟添加到我們的 `MyDataset` 類中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 實作練習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "下面的Class定義中有4個 `FIXME`。你能用正確的值替換它們嗎？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1715240547901,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "tpzGOri32Klj"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, base_df):\n",
    "        x_df = base_df.copy()  # Some operations below are in-place\n",
    "        y_df = x_df.pop(FIXME)\n",
    "        x_df = x_df.values / 255  # Normalize values from 0 to 1\n",
    "        x_df = x_df.reshape(-1, FIXME, FIXME, FIXME)\n",
    "        self.xs = torch.tensor(x_df).float().to(device)\n",
    "        self.ys = torch.tensor(y_df).to(device)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "        y = self.ys[idx]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "點擊下方的 `...` 查看解答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, base_df):\n",
    "        x_df = base_df.copy()  # Some operations below are in-place\n",
    "        y_df = x_df.pop('label')\n",
    "        x_df = x_df.values / 255  # Normalize values from 0 to 1\n",
    "        x_df = x_df.reshape(-1, IMG_CHS, IMG_WIDTH, IMG_HEIGHT)\n",
    "        self.xs = torch.tensor(x_df).float().to(device)\n",
    "        self.ys = torch.tensor(y_df).to(device)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "        y = self.ys[idx]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 建立資料載入器(DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "接下來，讓我們從資料集(Dataset)建立資料載入器(DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 實作練習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "以下其中一個函式呼叫缺少了 `shuffle=True` 參數。你能記得是哪一個並將它加回去嗎？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1715240550115,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "unf8Cz4WcK_M"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = MyDataset(train_df)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "train_N = len(train_loader.dataset)\n",
    "\n",
    "valid_data = MyDataset(valid_df)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "valid_N = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "點擊下方的 `...` 查看解答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "讓我們從資料載入器(DataLoader)中取得一個批次(batch)來確保它正常運作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715240550382,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "Z4xylt03dz1W",
    "outputId": "80447d85-302d-4549-976b-f4c3ac0f0644"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.6275, 0.6275, 0.6392,  ..., 0.6157, 0.6118, 0.6039],\n",
       "           [0.6353, 0.6314, 0.6431,  ..., 0.6235, 0.6157, 0.6078],\n",
       "           [0.6392, 0.6392, 0.6471,  ..., 0.6196, 0.6118, 0.6078],\n",
       "           ...,\n",
       "           [0.4627, 0.6784, 0.6706,  ..., 0.6706, 0.6667, 0.6784],\n",
       "           [0.6510, 0.6627, 0.6784,  ..., 0.6784, 0.6549, 0.5882],\n",
       "           [0.6157, 0.6588, 0.6706,  ..., 0.2863, 0.1961, 0.1098]]],\n",
       " \n",
       " \n",
       "         [[[0.2196, 0.2431, 0.2941,  ..., 0.5333, 0.5333, 0.5373],\n",
       "           [0.2196, 0.2471, 0.3020,  ..., 0.5333, 0.5373, 0.5412],\n",
       "           [0.2235, 0.2549, 0.3098,  ..., 0.5373, 0.5373, 0.5451],\n",
       "           ...,\n",
       "           [0.3333, 0.3686, 0.3922,  ..., 0.6353, 0.6353, 0.6392],\n",
       "           [0.3373, 0.3725, 0.3961,  ..., 0.6431, 0.6431, 0.6431],\n",
       "           [0.3373, 0.3686, 0.3961,  ..., 0.6431, 0.6431, 0.6431]]],\n",
       " \n",
       " \n",
       "         [[[0.4275, 0.4784, 0.5176,  ..., 0.6078, 0.6000, 0.5922],\n",
       "           [0.4314, 0.4824, 0.5255,  ..., 0.6196, 0.6118, 0.6000],\n",
       "           [0.4431, 0.4902, 0.5255,  ..., 0.6235, 0.6196, 0.6078],\n",
       "           ...,\n",
       "           [0.5137, 0.5647, 0.6000,  ..., 0.7569, 0.7490, 0.7451],\n",
       "           [0.5098, 0.5608, 0.5961,  ..., 0.7529, 0.7451, 0.7412],\n",
       "           [0.5137, 0.5569, 0.5961,  ..., 0.7490, 0.7451, 0.7412]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.3569, 0.3686, 0.3882,  ..., 0.7373, 0.7412, 0.7373],\n",
       "           [0.3569, 0.3725, 0.3882,  ..., 0.7451, 0.7451, 0.7412],\n",
       "           [0.3608, 0.3765, 0.3961,  ..., 0.7529, 0.7490, 0.7529],\n",
       "           ...,\n",
       "           [0.3333, 0.3490, 0.4157,  ..., 0.8314, 0.8314, 0.8353],\n",
       "           [0.3333, 0.3529, 0.4118,  ..., 0.8431, 0.8431, 0.8431],\n",
       "           [0.4980, 0.5059, 0.5020,  ..., 0.6980, 0.6980, 0.6980]]],\n",
       " \n",
       " \n",
       "         [[[0.6078, 0.6196, 0.6314,  ..., 0.7020, 0.7020, 0.6980],\n",
       "           [0.6157, 0.6275, 0.6392,  ..., 0.7059, 0.7059, 0.7020],\n",
       "           [0.6196, 0.6314, 0.6431,  ..., 0.6784, 0.7020, 0.7137],\n",
       "           ...,\n",
       "           [0.7451, 0.7608, 0.7765,  ..., 0.8745, 0.8745, 0.8667],\n",
       "           [0.7451, 0.7608, 0.7765,  ..., 0.8824, 0.8510, 0.7843],\n",
       "           [0.7373, 0.7529, 0.7686,  ..., 0.8745, 0.7529, 0.5882]]],\n",
       " \n",
       " \n",
       "         [[[0.7020, 0.6980, 0.6980,  ..., 0.6157, 0.6078, 0.6039],\n",
       "           [0.7098, 0.7098, 0.7098,  ..., 0.6275, 0.6235, 0.6235],\n",
       "           [0.7216, 0.7216, 0.7176,  ..., 0.6392, 0.6314, 0.6235],\n",
       "           ...,\n",
       "           [0.8745, 0.8745, 0.8745,  ..., 0.8039, 0.7882, 0.7843],\n",
       "           [0.8706, 0.8745, 0.8745,  ..., 0.8078, 0.7922, 0.7843],\n",
       "           [0.8706, 0.8667, 0.8784,  ..., 0.8078, 0.8000, 0.7882]]]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 6, 11, 21, 23,  0,  2,  4, 15, 15, 19, 11,  6, 23,  0,  5,  2,  3,  6,\n",
       "         21, 15, 18, 21,  6, 17, 11, 10, 22, 13, 13, 17, 21, 17],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "它看起來不同，但讓我們檢查 `shape` 來確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1715240552534,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "vannMV7sd6R_",
    "outputId": "627858a2-a4ed-467c-cf82-2b7c1a01c13f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1715240553488,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "YHJgP3A7d9lu",
    "outputId": "4a40ceb8-039b-4517-de8a-bdcb814c4164"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6biSPXKJ3ZZP"
   },
   "source": [
    "## 3.3 建立卷積模型(Convolutional Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppdkNb1A3ZZP"
   },
   "source": [
    "\n",
    "現今，許多資料科學家會從類似的專案借用其模型特性做為基礎來開始他們的專案。假設問題不是獨一無二的，那很有可能有人已經建立了表現良好的模型，並發布在如 [TensorFlow Hub](https://www.tensorflow.org/hub) 和 [NGC Catalog](https://ngc.nvidia.com/catalog/models) 等線上資源庫中。今天，我們將提供一個適合這個問題的模型。\n",
    "\n",
    "<img src=\"images/cnn.png\" width=180 />\n",
    "\n",
    "我們在課程中介紹了許多不同類型的層，在這裡我們將全部介紹並提供它們的文件連結。當有疑問時，請閱讀官方文件（或在[Stack Overflow](https://stackoverflow.com/)上提問）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1715240555184,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "p_bvGpMId_6q"
   },
   "outputs": [],
   "source": [
    "n_classes = 24\n",
    "kernel_size = 3\n",
    "flattened_img_size = 75 * 3 * 3\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # First convolution\n",
    "    nn.Conv2d(IMG_CHS, 25, kernel_size, stride=1, padding=1),  # 25 x 28 x 28\n",
    "    nn.BatchNorm2d(25),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),  # 25 x 14 x 14\n",
    "    # Second convolution\n",
    "    nn.Conv2d(25, 50, kernel_size, stride=1, padding=1),  # 50 x 14 x 14\n",
    "    nn.BatchNorm2d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.2),\n",
    "    nn.MaxPool2d(2, stride=2),  # 50 x 7 x 7\n",
    "    # Third convolution\n",
    "    nn.Conv2d(50, 75, kernel_size, stride=1, padding=1),  # 75 x 7 x 7\n",
    "    nn.BatchNorm2d(75),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),  # 75 x 3 x 3\n",
    "    # Flatten to Dense\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flattened_img_size, 512),\n",
    "    nn.Dropout(.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, n_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WsDr9gE3ZZP"
   },
   "source": [
    "### 3.3.1 [Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eHXRtWa3ZZP"
   },
   "source": [
    "<img src=\"images/conv2d.png\" width=300 />\n",
    "\n",
    "這些是我們的 2D 卷積層(Conv2D)。許多小型核心(kernel)會掃過輸入圖像並檢測對分類重要的特徵。模型中較早的卷積會檢測簡單的特徵，如線條。較後的卷積則會檢測更複雜的特徵。讓我們看看我們的第一個 Conv2D 層：\n",
    "```Python\n",
    "nn.Conv2d(IMG_CHS, 25, kernel_size, stride=1, padding=1)\n",
    "```\n",
    "25 指的是將要學習的過濾器(filter)數量。雖然 `kernel_size = 3`，PyTorch 會假設我們想要 3 x 3 的過濾器。步長(stride)指的是過濾器掃過圖像時的步長大小。填充(padding)代表的是由過濾器創建的輸出圖像的大小是否與輸入圖像大小一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiuMlsan3ZZQ"
   },
   "source": [
    "### 3.3.2 [BatchNormalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp72aAnK3ZZQ"
   },
   "source": [
    "\n",
    "\n",
    "就像正規化(Normalization)我們的輸入的資料一樣，批次正規化(BatchNormalization)會調整隱藏層中的值以改善訓練。[在這裡詳細了解更多](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)。\n",
    "\n",
    "關於批次正規化層(BatchNormalization)的最佳放置位置存在爭議。這個 [Stack Overflow](https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout) 貼文彙整了許多觀點。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twarf_s63ZZQ"
   },
   "source": [
    "### 3.3.3 [MaxPool2D](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoNIzZZW3ZZQ"
   },
   "source": [
    "<img src=\"images/maxpool2d.png\" width=300 />\n",
    "\n",
    "最大池化(MaxPool2D)會取一個圖像並基本上將其縮小到較低的解析度。這樣做是為了幫助模型對橫移（物體左右移動）具有強韌性(robust)，同時也使我們的模型更快速。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzHlBRja3ZZQ"
   },
   "source": [
    "### 3.3.4 [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJjrPvkm3ZZQ"
   },
   "source": [
    "<img src=\"images/dropout.png\" width=360 />\n",
    "\n",
    " Dropout 是一種防止過度擬合(overfitting)的技術。Dropout 隨機選擇一部分神經元並將其關閉，使它們在特定的前向或後向傳播中不參與。這有助於確保網路具有強韌性和備援性(redundant)，並且不依賴於任何一個區域來得出答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYPkQPA3ZZQ"
   },
   "source": [
    "### 3.3.5 [Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuMt-DpZ3ZZQ"
   },
   "source": [
    "\n",
    "\n",
    "Flatten 將一層的多維輸出展平成一維陣列。輸出被稱為特徵向量(feature vector)，並將連接到最終的分類層。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSur4TGx3ZZQ"
   },
   "source": [
    "### 3.3.6 [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PATqMedY3ZZQ"
   },
   "source": [
    "\n",
    "我們在先前的模型中已經見過密集線性層(dense linear layers)。我們的第一個密集層（512 個單元）將特徵向量作為輸入，並學習哪些特徵會對特定分類有所貢獻。第二個密集層（24 個單元）是最終的分類層，輸出我們的預測結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_opXKGWj3ZZQ"
   },
   "source": [
    "## 3.4 Summarizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eo6eRrp23ZZQ"
   },
   "source": [
    "\n",
    "這可能感覺像是很多資訊，但別擔心。現在不需要完全理解所有內容就能有效地訓練卷積模型。最重要的是我們知道它們可以幫助從圖像中提取有用的資訊，並可用於分類任務。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1715240557183,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "2IAS92gZwcP3",
    "outputId": "56678948-aed0-4aa3-dde9-b8cecbaff44d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Sequential(\n",
       "    (0): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(25, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(50, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): Flatten(start_dim=1, end_dim=-1)\n",
       "    (14): Linear(in_features=675, out_features=512, bias=True)\n",
       "    (15): Dropout(p=0.3, inplace=False)\n",
       "    (16): ReLU()\n",
       "    (17): Linear(in_features=512, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.compile(model.to(device))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "由於我們嘗試解決的問題仍然相同（分類 ASL 圖像），我們將繼續使用相同的 `loss_function` 和  `accuracy` 指標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1715240559055,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "-BUIQ5COwsri"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1715240559790,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "SniWnvc5NSkA"
   },
   "outputs": [],
   "source": [
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBgbUNDH3ZZR"
   },
   "source": [
    "### 3.5 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsS9zDKh3ZZR"
   },
   "source": [
    "儘管模型架構非常不同，但訓練過程看起來完全相同。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 實作練習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "這些是與之前相同的 `train` 和 `validate` 函式，但它們已被混合。你能正確命名每個函式並替換 `FIXME` 嗎？\n",
    "\n",
    "其中一個應該有 `model.train`，另一個應該有 `model.eval`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1715240562885,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "e9R0vJA8NQUW"
   },
   "outputs": [],
   "source": [
    "def FIXME():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.FIXME()\n",
    "    with torch.no_grad():\n",
    "        for x, y in FIXME:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    print('FIXME - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1715240561357,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "wr-X8QkVv9I7"
   },
   "outputs": [],
   "source": [
    "def FIXME():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.FIXME()\n",
    "    for x, y in FIXME:\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print('FIXME - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "點擊下方兩個 `...` 查看解答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "executionInfo": {
     "elapsed": 430665,
     "status": "error",
     "timestamp": 1715240995537,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "qOYsrlmUwyyI",
    "outputId": "ccbb497f-8f23-43c3-85c4-81f47c98728d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train - Loss: 265.9026 Accuracy: 0.9071\n",
      "Valid - Loss: 33.6062 Accuracy: 0.9506\n",
      "Epoch: 1\n",
      "Train - Loss: 15.6663 Accuracy: 0.9950\n",
      "Valid - Loss: 20.6965 Accuracy: 0.9672\n",
      "Epoch: 2\n",
      "Train - Loss: 14.7827 Accuracy: 0.9952\n",
      "Valid - Loss: 16.0878 Accuracy: 0.9647\n",
      "Epoch: 3\n",
      "Train - Loss: 9.8377 Accuracy: 0.9965\n",
      "Valid - Loss: 14.8248 Accuracy: 0.9738\n",
      "Epoch: 4\n",
      "Train - Loss: 11.2571 Accuracy: 0.9958\n",
      "Valid - Loss: 15.5076 Accuracy: 0.9710\n",
      "Epoch: 5\n",
      "Train - Loss: 4.2680 Accuracy: 0.9987\n",
      "Valid - Loss: 14.3364 Accuracy: 0.9739\n",
      "Epoch: 6\n",
      "Train - Loss: 7.9964 Accuracy: 0.9972\n",
      "Valid - Loss: 15.4875 Accuracy: 0.9808\n",
      "Epoch: 7\n",
      "Train - Loss: 11.2621 Accuracy: 0.9961\n",
      "Valid - Loss: 10.4677 Accuracy: 0.9796\n",
      "Epoch: 8\n",
      "Train - Loss: 0.4117 Accuracy: 0.9999\n",
      "Valid - Loss: 7.8629 Accuracy: 0.9847\n",
      "Epoch: 9\n",
      "Train - Loss: 0.1026 Accuracy: 1.0000\n",
      "Valid - Loss: 9.1475 Accuracy: 0.9848\n",
      "Epoch: 10\n",
      "Train - Loss: 13.4166 Accuracy: 0.9956\n",
      "Valid - Loss: 17.3810 Accuracy: 0.9777\n",
      "Epoch: 11\n",
      "Train - Loss: 1.6007 Accuracy: 0.9995\n",
      "Valid - Loss: 27.2444 Accuracy: 0.9696\n",
      "Epoch: 12\n",
      "Train - Loss: 6.7672 Accuracy: 0.9975\n",
      "Valid - Loss: 21.9307 Accuracy: 0.9738\n",
      "Epoch: 13\n",
      "Train - Loss: 1.1084 Accuracy: 0.9996\n",
      "Valid - Loss: 17.4599 Accuracy: 0.9795\n",
      "Epoch: 14\n",
      "Train - Loss: 7.9457 Accuracy: 0.9979\n",
      "Valid - Loss: 20.2554 Accuracy: 0.9713\n",
      "Epoch: 15\n",
      "Train - Loss: 3.2461 Accuracy: 0.9987\n",
      "Valid - Loss: 30.6214 Accuracy: 0.9603\n",
      "Epoch: 16\n",
      "Train - Loss: 4.7779 Accuracy: 0.9984\n",
      "Valid - Loss: 43.2964 Accuracy: 0.9656\n",
      "Epoch: 17\n",
      "Train - Loss: 0.9755 Accuracy: 0.9997\n",
      "Valid - Loss: 27.2992 Accuracy: 0.9678\n",
      "Epoch: 18\n",
      "Train - Loss: 5.4125 Accuracy: 0.9981\n",
      "Valid - Loss: 30.5123 Accuracy: 0.9757\n",
      "Epoch: 19\n",
      "Train - Loss: 1.2308 Accuracy: 0.9996\n",
      "Valid - Loss: 38.7601 Accuracy: 0.9782\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVytGlnl3ZZR"
   },
   "source": [
    "### 3.5.1 結果討論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukd8Kk8l3ZZR"
   },
   "source": [
    "\n",
    "\n",
    "看起來這個模型有顯著的改進！訓練準確度(accuracy)非常高，驗證準確度(validation accuracy)也有所提高。這是一個很好的結果，我們只需要換一個新模型就做到了。\n",
    "\n",
    "你可能已經注意到驗證準確度(validation accuracy)在跳動。這表明我們的模型仍然沒有完美地泛化(generalizing)。幸運的是，我們還可以做更多事情。讓我們在下一個講座中討論它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsOHIy5F3ZZR"
   },
   "source": [
    "## 3.6 總結"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcIRdSur3ZZR"
   },
   "source": [
    "\n",
    "\n",
    "在本節中，我們使用了幾種新型的層來實現卷積神經網路(CNN)，它比上一節使用的簡單的模型表現得更好。希望你開始對使用準備好的資料來建立和訓練模型的整體過程越來越熟悉。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0wFCmbK3ZZS"
   },
   "source": [
    "### 3.6.1 清空記憶體\n",
    "\n",
    "\n",
    "在繼續之前，請執行以下程式碼區塊(Cell)以清空 GPU 記憶體。這是繼續下一個notebook所必需的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ul7wgax3ZZS"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kMR2FOK3ZZS"
   },
   "source": [
    "### 3.6.2 下一步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13FglbMX3ZZS"
   },
   "source": [
    "\n",
    "\n",
    "在過去的幾個部分中，你專注於模型的創建和訓練。為了進一步提高性能，你現在將注意力轉向資料增強(data augmentation)，這是一系列技術，將允許你的模型在比原始可用資料更多更好的資料上進行訓練。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEzcSC6x3ZZS"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
